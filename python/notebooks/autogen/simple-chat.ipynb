{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autogen Workflow\n",
    "\n",
    "Made up of:\n",
    "\n",
    "```text\n",
    "Workflow (1) -> (*) Agents\n",
    "    Agents (1) -> (*) skills\n",
    "```\n",
    "\n",
    "References:\n",
    "\n",
    "- [Autogenstudio](https://microsoft.github.io/autogen/docs/autogen-studio/getting-started)\n",
    "\n",
    "## Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv==1.0.1 openai==1.35.9 gradio==4.39.0 pyautogen==0.2.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages and create the Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Union, Optional\n",
    "from pathlib import Path\n",
    "import autogen\n",
    "from autogen import ConversableAgent, ChatResult\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loand the environment variables and prepare the Autogen configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "model = os.getenv(\"GPT_MODEL\")\n",
    "endpoint=os.getenv(\"ENDPOINT\")\n",
    "api_key=os.getenv(\"API_KEY\")\n",
    "api_version=os.getenv(\"API_VERSION\")\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"base_url\": endpoint,\n",
    "        \"api_key\": api_key,\n",
    "        \"model\": model,\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": model,\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list,    \n",
    "    \"cache_seed\": None, # Enable caching\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting classes and methods\n",
    "\n",
    "The following supporting classes come from Autogen Studio: a tool \"to help you rapidly prototype multi-agent solutions for your tasks, we are introducing AutoGen Studio, an interface powered by AutoGen.\"\n",
    "\n",
    "1. `ExtendedConversableAgent`: Extends the ConversableAgent class with the ability to tap into the conversation between agents as it is happeing.\n",
    "2. `process_message`: the function to use to tap into the messages.\n",
    "3. `chat_history`: the history of the conversation being listen to.\n",
    "\n",
    "Refences:\n",
    "\n",
    "- [autogenstudio](https://microsoft.github.io/autogen/blog/2023/12/01/AutoGenStudio/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def process_message(\n",
    "    sender: autogen.Agent,\n",
    "    receiver: autogen.Agent,\n",
    "    message: Dict,\n",
    "    request_reply: bool = False,\n",
    "    silent: bool = False,\n",
    "    sender_type: str = \"agent\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Processes the message and adds it to the agent history.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        sender: The sender of the message.\n",
    "        receiver: The receiver of the message.\n",
    "        message: The message content.\n",
    "        request_reply: If set to True, the message will be added to agent history.\n",
    "        silent: determining verbosity.\n",
    "        sender_type: The type of the sender of the message.\n",
    "    \"\"\"\n",
    "\n",
    "    message = message if isinstance(message, dict) else {\n",
    "        \"content\": message, \"role\": \"user\"}\n",
    "    message_payload = {\n",
    "        \"recipient\": receiver.name,\n",
    "        \"sender\": sender.name,\n",
    "        \"message\": message,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"sender_type\": sender_type,\n",
    "        \"message_type\": \"agent_message\",\n",
    "    }\n",
    "    if message[\"content\"]:\n",
    "        #print(message_payload)\n",
    "        chat_history.append(message_payload)\n",
    "\n",
    "\n",
    "class ExtendedConversableAgent(ConversableAgent):\n",
    "    def __init__(self, message_processor=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.message_processor = message_processor\n",
    "        self.history = []\n",
    "\n",
    "    def receive(\n",
    "        self,\n",
    "        message: Union[Dict, str],\n",
    "        sender: autogen.Agent,\n",
    "        request_reply: Optional[bool] = None,\n",
    "        silent: Optional[bool] = False,\n",
    "    ):\n",
    "        if self.message_processor:\n",
    "            self.message_processor(sender, self, message,\n",
    "                                   request_reply, silent, sender_type=\"agent\")\n",
    "        # print(f\"Sender: {sender.name}\")\n",
    "        # print(f\"Message: {message}\")\n",
    "        super().receive(message, sender, request_reply, silent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the local Autogen code executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the code executor\n",
    "work_dir = Path(\"coding\")\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "executor = LocalCommandLineCodeExecutor(work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config the Autogen agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent without an LLM but with code execution capabilities.\n",
    "user = ExtendedConversableAgent(name=\"user\",\n",
    "                                max_consecutive_auto_reply=5,\n",
    "                                code_execution_config={\"executor\": executor},\n",
    "                                human_input_mode=\"NEVER\",\n",
    "                                is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"].lower() or msg[\"content\"]==\"\",\n",
    "                                message_processor=process_message,\n",
    "                                )\n",
    "\n",
    "# Create the agent that uses the LLM.\n",
    "assistant = ExtendedConversableAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a general AI assistant that can answer questions and generate code.\",\n",
    "    llm_config=llm_config,    \n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"].lower() or msg[\"content\"]==\"\" or \"exitcode: 0\" in msg[\"content\"],\n",
    "    message_processor=process_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a chat conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message: str,clear=False,silent=True,max_turns=-1)->Tuple[float,str]:\n",
    "    if clear:\n",
    "        chat_history.clear()\n",
    "    start_time = time.time()\n",
    "    # The conversation history is being recorded by the process_message function in the chat_history array\n",
    "    result : ChatResult = None\n",
    "    if max_turns>0:\n",
    "        result = user.initiate_chat(assistant,message=message,clear_history=clear,silent=silent,max_turns=max_turns)\n",
    "    else:\n",
    "        result = user.initiate_chat(assistant,message=message,clear_history=clear,silent=silent)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    return (duration,result.summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_history()->None:\n",
    "    for message in chat_history:\n",
    "        print(f\"{message['sender']} : {message['message']['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a conversation between the user and the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat(\"List is one good restaurant in Miami.\",clear=True)\n",
    "chat(\"What is another one?\")\n",
    "chat(\"Write a python app to find 1001st prime number?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
